{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878625e0",
   "metadata": {},
   "source": [
    "### Group members: Niharika Rasthapuram, Tyler Blankenship, Kao Takahama, Tyler Selby, Zach Seitz, Safal Lamichhane \n",
    "\n",
    "### Due Date: 3/5/23\n",
    "\n",
    "### Using what we have learned in Unit5 of Pandas to analyze SP500.csv file with Series and DataFrame operations. Please find answers to the following questions:\n",
    "    \n",
    "### 1) Generate a brief statistic summary for corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d98eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Open          High           Low         Close     Adj Close  \\\n",
      "count  17191.000000  17191.000000  17191.000000  17191.000000  17191.000000   \n",
      "mean     546.966024    550.229233    543.522697    547.091391    547.091391   \n",
      "std      643.238592    646.567762    639.645155    643.342927    643.342927   \n",
      "min       16.660000     16.660000     16.660000     16.660000     16.660000   \n",
      "25%       85.419998     86.130001     84.760002     85.424999     85.424999   \n",
      "50%      164.369995    165.050003    163.710007    164.289993    164.289993   \n",
      "75%     1073.684998   1082.705017   1065.224976   1073.669983   1073.669983   \n",
      "max     2867.229980   2872.870117   2851.479980   2872.870117   2872.870117   \n",
      "\n",
      "             Volume  \n",
      "count  1.719100e+04  \n",
      "mean   8.945411e+08  \n",
      "std    1.531001e+09  \n",
      "min    6.800000e+05  \n",
      "25%    8.685000e+06  \n",
      "50%    8.794000e+07  \n",
      "75%    1.110950e+09  \n",
      "max    1.145623e+10  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in the data from .csv file\n",
    "data = pd.read_csv('SP500.csv')\n",
    "\n",
    "# use .describe() method to print statistics for the data\n",
    "print(data.describe())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d9f84",
   "metadata": {},
   "source": [
    "### 2) Sort daily gain/loss for January of 2018 and store the result back to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08420f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Gain/Loss\n",
      "Date                 \n",
      "2018-01-02 -12.080079\n",
      "2018-01-03 -15.209961\n",
      "2018-01-04  -4.679931\n",
      "2018-01-05 -11.819824\n",
      "2018-01-08  -5.040039\n",
      "2018-01-09  -0.140137\n",
      "2018-01-10  -2.679931\n",
      "2018-01-11 -14.590088\n",
      "2018-01-12 -16.060058\n",
      "2018-01-16  22.540039\n",
      "2018-01-17 -17.570069\n",
      "2018-01-18   4.369873\n",
      "2018-01-19  -7.699951\n",
      "2018-01-22 -23.810059\n",
      "2018-01-23  -4.079834\n",
      "2018-01-24   7.879883\n",
      "2018-01-25   6.989990\n",
      "2018-01-26 -25.390137\n",
      "2018-01-29  13.699951\n",
      "2018-01-30  10.310058\n",
      "2018-01-31   8.599853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in the data from .csv file\n",
    "data = pd.read_csv('SP500.csv')\n",
    "\n",
    "# convert the values in the date column to pandas datetime values\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# find gain/loss\n",
    "open_price = data['Open']\n",
    "closing_price = data['Close']\n",
    "gain_loss = (open_price - closing_price)\n",
    "\n",
    "# add a column for gain/loss to the original dataframe\n",
    "data['Gain/Loss'] = gain_loss\n",
    "\n",
    "# create a new dataframe by making a copy of only the date and gain/loss columns from the old dataframe\n",
    "dailyGL = data[['Date', 'Gain/Loss']].copy()\n",
    "dailyGL.set_index('Date', inplace=True)\n",
    "dailyGL.sort_values(by='Date', ascending = True, inplace = True)\n",
    "\n",
    "# final dataframe containing only the month of Jan 2018 which will be made into .csv file\n",
    "jan18GL = dailyGL.loc['2018-01-01':'2018-01-31']\n",
    "print(jan18GL)\n",
    "\n",
    "# use the new dataframe to create a new .csv file\n",
    "jan18GL.to_csv('Jan2018GL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7080a36",
   "metadata": {},
   "source": [
    "### 3) Find all of the daily gains reach 20% and above and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cac764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date        Open         High        Low        Close  \\\n",
      "14789  2008-10-13  912.750000  1006.929993  912.75000  1003.349976   \n",
      "14800  2008-10-28  848.919983   940.510010  845.27002   940.510010   \n",
      "\n",
      "         Adj Close      Volume  Percent Change  \n",
      "14789  1003.349976  7263370000       11.580037  \n",
      "14800   940.510010  7096950000       10.789006  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SP500.csv')\n",
    "\n",
    "# Calculate the daily percent change in the Close column\n",
    "df['Percent Change'] = df['Close'].pct_change() * 100\n",
    "\n",
    "# Filter rows where the percent change is >= 10% but i took 10 because 20% gives empty dataframe\n",
    "large_gains = df.loc[df['Percent Change'] >= 10]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(large_gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77c9cd",
   "metadata": {},
   "source": [
    "### 4) the highest daily gain and its date, the highest daily loss and its date,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e37b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest daily gain: 2008-10-13 (11.58%)\n",
      "Highest daily loss: 1987-10-19 (-20.47%)\n"
     ]
    }
   ],
   "source": [
    "# Need to calculate Percentage change again but the data is already available from previous Question\n",
    "# df['Percent Change'] = df['Close'].pct_change() * 100\n",
    "\n",
    "# Find the row with the highest percent change (i.e., highest daily gain)\n",
    "highest_gain_row = df.loc[df['Percent Change'].idxmax()]\n",
    "\n",
    "# Find the row with the lowest percent change (i.e., highest daily loss)\n",
    "highest_loss_row = df.loc[df['Percent Change'].idxmin()]\n",
    "\n",
    "# Print the date and percent change for the highest daily gain and loss\n",
    "print(f'Highest daily gain: {highest_gain_row[\"Date\"]} ({highest_gain_row[\"Percent Change\"]:.2f}%)')\n",
    "print(f'Highest daily loss: {highest_loss_row[\"Date\"]} ({highest_loss_row[\"Percent Change\"]:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2a229",
   "metadata": {},
   "source": [
    "### 5) the most daily transaction volume and its date,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c373913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest daily volume was 11456230000 on 2008-10-10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SP500.csv')\n",
    "\n",
    "max_vol_daily = df['Volume'].idxmax()\n",
    "\n",
    "print(f\"The highest daily volume was {df.iloc[max_vol_daily][-1]} on {df.iloc[max_vol_daily][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336290e0",
   "metadata": {},
   "source": [
    "### 6) a monthly report for year 2017-2018, which has monthly average open price, close price, transaction volume and gain/loss, and a query to find all of the months which have certain range of open prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55949a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly report:\n",
      "            Avg Monthly Open  Avg Monthly Close  Avg Monthly Volume  \\\n",
      "Date                                                                  \n",
      "2017-01-31       2273.531970        2275.115979        3.524159e+09   \n",
      "2017-02-28       2325.585282        2329.910542        3.640127e+09   \n",
      "2017-03-31       2366.868705        2366.822170        3.545555e+09   \n",
      "2017-04-30       2360.150005        2359.309455        3.435035e+09   \n",
      "2017-05-31       2394.470004        2395.345881        3.618508e+09   \n",
      "2017-06-30       2434.683605        2433.985451        3.681931e+09   \n",
      "2017-07-31       2453.039490        2454.102502        3.158470e+09   \n",
      "2017-08-31       2456.749968        2456.223070        3.070262e+09   \n",
      "2017-09-30       2491.332495        2492.841040        3.316899e+09   \n",
      "2017-10-31       2555.807273        2556.997270        3.221435e+09   \n",
      "2017-11-30       2590.306164        2593.605736        3.484441e+09   \n",
      "2017-12-31       2666.069995        2664.340527        3.262560e+09   \n",
      "2018-01-31       2785.686651        2789.803816        3.660006e+09   \n",
      "2018-02-28       2710.269467        2705.155248        4.188390e+09   \n",
      "2018-03-31       2707.860003        2702.773821        3.635705e+09   \n",
      "2018-04-30       2656.397986        2653.903967        3.295703e+09   \n",
      "\n",
      "            Avg Monthly Gain/Loss  \n",
      "Date                               \n",
      "2017-01-31               1.584009  \n",
      "2017-02-28               4.325260  \n",
      "2017-03-31              -0.046535  \n",
      "2017-04-30              -0.840550  \n",
      "2017-05-31               0.875877  \n",
      "2017-06-30              -0.698153  \n",
      "2017-07-31               1.063013  \n",
      "2017-08-31              -0.526898  \n",
      "2017-09-30               1.508545  \n",
      "2017-10-31               1.189997  \n",
      "2017-11-30               3.299572  \n",
      "2017-12-31              -1.729468  \n",
      "2018-01-31               4.117164  \n",
      "2018-02-28              -5.114219  \n",
      "2018-03-31              -5.086182  \n",
      "2018-04-30              -2.494018  \n",
      "\n",
      "\n",
      "The following months have an average open price between 1500 and 2000:\n",
      "\n",
      "2000-03-31   2000-04-30   2000-05-31   2000-06-30   2000-07-31   2000-08-31   2000-09-30   2000-10-31   2000-11-30   2000-12-31   2001-01-31   2001-02-28   2001-03-31   2001-04-30   2001-05-31   2001-06-30   2001-07-31   2001-08-31   2001-09-30   2001-10-31   2001-11-30   2001-12-31   2002-01-31   2002-02-28   2002-03-31   2002-04-30   2002-05-31   2002-06-30   2002-07-31   2002-08-31   2002-09-30   2002-10-31   2002-11-30   2002-12-31   2003-01-31   2003-02-28   2003-03-31   2003-04-30   2003-05-31   2003-06-30   2003-07-31   2003-08-31   2003-09-30   2003-10-31   2003-11-30   2003-12-31   2004-01-31   2004-02-29   2004-03-31   2004-04-30   2004-05-31   2004-06-30   2004-07-31   2004-08-31   2004-09-30   2004-10-31   2004-11-30   2004-12-31   2005-01-31   2005-02-28   2005-03-31   2005-04-30   2005-05-31   2005-06-30   2005-07-31   2005-08-31   2005-09-30   2005-10-31   2005-11-30   2005-12-31   2006-01-31   2006-02-28   2006-03-31   2006-04-30   2006-05-31   2006-06-30   2006-07-31   2006-08-31   2006-09-30   2006-10-31   2006-11-30   2006-12-31   2007-01-31   2007-02-28   2007-03-31   2007-04-30   2007-05-31   2007-06-30   2007-07-31   2007-08-31   2007-09-30   2007-10-31   2007-11-30   2007-12-31   2008-01-31   2008-02-29   2008-03-31   2008-04-30   2008-05-31   2008-06-30   2008-07-31   2008-08-31   2008-09-30   2008-10-31   2008-11-30   2008-12-31   2009-01-31   2009-02-28   2009-03-31   2009-04-30   2009-05-31   2009-06-30   2009-07-31   2009-08-31   2009-09-30   2009-10-31   2009-11-30   2009-12-31   2010-01-31   2010-02-28   2010-03-31   2010-04-30   2010-05-31   2010-06-30   2010-07-31   2010-08-31   2010-09-30   2010-10-31   2010-11-30   2010-12-31   2011-01-31   2011-02-28   2011-03-31   2011-04-30   2011-05-31   2011-06-30   2011-07-31   2011-08-31   2011-09-30   2011-10-31   2011-11-30   2011-12-31   2012-01-31   2012-02-29   2012-03-31   2012-04-30   2012-05-31   2012-06-30   2012-07-31   2012-08-31   2012-09-30   2012-10-31   2012-11-30   2012-12-31   2013-01-31   2013-02-28   2013-03-31   2013-04-30   2013-05-31   2013-06-30   2013-07-31   2013-08-31   2013-09-30   2013-10-31   2013-11-30   2013-12-31   2014-01-31   2014-02-28   2014-03-31   2014-04-30   2014-05-31   2014-06-30   2014-07-31   2014-08-31   2014-09-30   2014-10-31   2014-11-30   2014-12-31   2015-01-31   2015-02-28   2015-03-31   2015-04-30   2015-05-31   2015-06-30   2015-07-31   2015-08-31   2015-09-30   2015-10-31   2015-11-30   2015-12-31   2016-01-31   2016-02-29   2016-03-31   "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by_month(csv, year_start, year_end):\n",
    "    \"\"\"Group CSV records by month, beginning at year_start and ending at year_end.\n",
    "    CSV must include a date column.\n",
    "    Year_start and year_end can be integers or strings.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Cast to ints and add 1 to year_end (for indexing)\n",
    "    if type(year_start) != int or type(year_end) != int:\n",
    "        year_start = int(year_start)\n",
    "        year_end - int(year_end) + 1\n",
    "    \n",
    "    # Convert date string into datatime objects and set as index (for grouping)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    # Get data for specified date range\n",
    "    years = df.loc[str(year_start): str(year_end + 1)]\n",
    "    \n",
    "    # Group by month\n",
    "    months = years.groupby(pd.Grouper(freq=\"M\"))\n",
    "    \n",
    "    return months\n",
    "\n",
    "def query(csv, open_start, open_end, year_start=1950, year_end=2023):\n",
    "    \"\"\"Query the csv for the all months in which the avg opening price\n",
    "    is between open_start (lower bound) and open_end (upper bound).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Query for results between specified open prices\n",
    "    df.query(f'Open > {open_start} and  Open < {open_end}', inplace=True)\n",
    "    # Convert date string into datatime objects and set as index (for grouping)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    # Group results by month\n",
    "    months = df.groupby(pd.Grouper(freq=\"M\"))\n",
    "    return months\n",
    "#     return [key.date() for key, item in months]\n",
    "\n",
    "\n",
    "#### Get average monthly values ####\n",
    "months = group_by_month(\"SP500.csv\", 2017, 2018)\n",
    "\n",
    "data = {\"Avg Monthly Open\": months[\"Open\"].mean(),\n",
    "        \"Avg Monthly Close\": months[\"Close\"].mean(),\n",
    "        \"Avg Monthly Volume\": months[\"Volume\"].mean(),\n",
    "        \"Avg Monthly Gain/Loss\": (months.apply(lambda x: x['Adj Close'] - x['Open'])).groupby('Date').mean()\n",
    "       }\n",
    "\n",
    "# Amalgamate data, print\n",
    "report = pd.concat(data, axis=1)\n",
    "print(f\"Monthly report:\\n{report}\\n\\n\")\n",
    "\n",
    "\n",
    "#### Query for open prices in range 1500-2000 ####\n",
    "print(\"The following months have an average open price between 1500 and 2000:\\n\")\n",
    "results = query('SP500.csv', 1500, 2000)\n",
    "\n",
    "for key, item in results:\n",
    "    print(key.date(), end=\"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180445e6",
   "metadata": {},
   "source": [
    "### 7) a yearly report which has annual average open price, close price, transaction volume and gain/loss from 1950 to 2018, and the most profitable year,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feede660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly report:\n",
      "            Avg Yearly Open  Avg Yearly Close  Avg Yearly Volume  \\\n",
      "Date                                                               \n",
      "1950-12-31        18.397269         18.397269       2.009237e+06   \n",
      "1951-12-31        22.321888         22.321888       1.717590e+06   \n",
      "1952-12-31        24.496160         24.496160       1.308160e+06   \n",
      "1953-12-31        24.722590         24.722590       1.413147e+06   \n",
      "1954-12-31        29.724087         29.724087       2.269762e+06   \n",
      "...                     ...               ...                ...   \n",
      "2014-12-31      1930.754485       1931.376110       3.354783e+09   \n",
      "2015-12-31      2061.268016       2061.067741       3.655629e+09   \n",
      "2016-12-31      2094.091550       2094.651264       3.905232e+09   \n",
      "2017-12-31      2448.275888       2449.076379       3.412303e+09   \n",
      "2018-12-31      2715.895794       2713.829129       3.687696e+09   \n",
      "\n",
      "            Avg Yearly Gain/Loss  \n",
      "Date                              \n",
      "1950-12-31              0.000000  \n",
      "1951-12-31              0.000000  \n",
      "1952-12-31              0.000000  \n",
      "1953-12-31              0.000000  \n",
      "1954-12-31              0.000000  \n",
      "...                          ...  \n",
      "2014-12-31              0.621625  \n",
      "2015-12-31             -0.200275  \n",
      "2016-12-31              0.559714  \n",
      "2017-12-31              0.800491  \n",
      "2018-12-31             -2.066665  \n",
      "\n",
      "[69 rows x 4 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by_year(csv, year_start, year_end):\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Cast to ints and add 1 to year_end (for indexing)\n",
    "    if type(year_start) != int or type(year_end) != int:\n",
    "        year_start = int(year_start)\n",
    "        year_end - int(year_end) + 1\n",
    "    \n",
    "    # Convert date string into datatime objects and set as index (for grouping)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    # Get data for specified date range\n",
    "    years = df.loc[str(year_start): str(year_end + 1)]\n",
    "    \n",
    "    # Group by year\n",
    "    period = years.groupby(pd.Grouper(freq=\"Y\"))\n",
    "    \n",
    "    return period\n",
    "\n",
    "period = group_by_year(\"SP500.csv\", 1950, 2018)\n",
    "\n",
    "data = {\"Avg Yearly Open\": period[\"Open\"].mean(),\n",
    "        \"Avg Yearly Close\": period[\"Close\"].mean(),\n",
    "        \"Avg Yearly Volume\": period[\"Volume\"].mean(),\n",
    "        \"Avg Yearly Gain/Loss\": (period.apply(lambda x: x['Adj Close'] - x['Open'])).groupby('Date').mean()\n",
    "       }\n",
    "\n",
    "# Amalgamate data, print\n",
    "report = pd.concat(data, axis=1)\n",
    "print(f\"Yearly report:\\n{report}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147c735",
   "metadata": {},
   "source": [
    "### 8) a every other five year report which has every five year average open price, close price, transaction volume and gain/loss from 1950 to 2018, and the most profitable five year,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67eba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5Y report:\n",
      "            Avg 5Y Open  Avg 5Y Close  Avg 5Y Volume  Avg 5Y Gain/Loss\n",
      "Date                                                                  \n",
      "1950-12-31    18.397269     18.397269   2.009237e+06          0.000000\n",
      "1955-12-31    28.376188     28.376188   1.857935e+06          0.000000\n",
      "1960-12-31    50.114611     50.114611   2.736270e+06          0.000000\n",
      "1965-12-31    73.601836     73.616121   4.707107e+06          0.014285\n",
      "1970-12-31    91.113033     91.114550   1.066547e+07          0.001517\n",
      "1975-12-31    96.747147     96.742029   1.608932e+07         -0.005119\n",
      "1980-12-31   103.580863    103.618290   2.957275e+07          0.037427\n",
      "1985-12-31   151.010736    151.073433   7.949703e+07          0.062698\n",
      "1990-12-31   289.269027    289.363798   1.627407e+08          0.094771\n",
      "1995-12-31   448.801242    449.028164   2.565800e+08          0.226922\n",
      "2000-12-31  1075.435091   1075.990895   6.898599e+08          0.555804\n",
      "2005-12-31  1097.989380   1097.938520   1.478513e+09         -0.050860\n",
      "2010-12-31  1218.753391   1218.863129   4.162387e+09          0.109738\n",
      "2015-12-31  1656.565086   1657.088005   3.622007e+09          0.522919\n",
      "2020-12-31  2332.561434   2332.860358   3.663202e+09          0.298924\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by_5Y(csv, year_start, year_end):\n",
    "    \n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Cast to ints and add 1 to year_end (for indexing)\n",
    "    if type(year_start) != int or type(year_end) != int:\n",
    "        year_start = int(year_start)\n",
    "        year_end - int(year_end) + 1\n",
    "    \n",
    "    # Convert date string into datatime objects and set as index (for grouping)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    # Get data for specified date range\n",
    "    years = df.loc[str(year_start): str(year_end + 1)]\n",
    "    \n",
    "    # Group by 5Y period\n",
    "    period = years.groupby(pd.Grouper(freq=\"5Y\"))\n",
    "    \n",
    "    return period\n",
    "\n",
    "period = group_by_5Y(\"SP500.csv\", 1950, 2018)\n",
    "\n",
    "data = {\"Avg 5Y Open\": period[\"Open\"].mean(),\n",
    "        \"Avg 5Y Close\": period[\"Close\"].mean(),\n",
    "        \"Avg 5Y Volume\": period[\"Volume\"].mean(),\n",
    "        \"Avg 5Y Gain/Loss\": (period.apply(lambda x: x['Adj Close'] - x['Open'])).groupby('Date').mean()\n",
    "       }\n",
    "\n",
    "# Amalgamate data, print\n",
    "report = pd.concat(data, axis=1)\n",
    "print(f\"5Y report:\\n{report}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e277b8",
   "metadata": {},
   "source": [
    "### Using what we have learned in Unit5 of Pandas to analyze Sacramentorealestatetransactions.csv file with Series and DataFrame operations. Please find answers to the following questions:\n",
    "\n",
    "### 9) Regroup the data first by city name, then by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45068707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city             type        \n",
      "ANTELOPE         Condo           115000.000000\n",
      "                 Residential     236168.156250\n",
      "AUBURN           Condo           260000.000000\n",
      "                 Multi-Family    285000.000000\n",
      "                 Residential     494818.000000\n",
      "CAMERON PARK     Condo           119000.000000\n",
      "                 Residential     286562.500000\n",
      "CARMICHAEL       Condo           190544.666667\n",
      "                 Residential     314238.882353\n",
      "CITRUS HEIGHTS   Condo            92625.000000\n",
      "                 Multi-Family    256054.000000\n",
      "                 Residential     190866.187500\n",
      "COOL             Residential     300000.000000\n",
      "DIAMOND SPRINGS  Residential     216033.000000\n",
      "EL DORADO        Residential     247000.000000\n",
      "EL DORADO HILLS  Residential     491698.956522\n",
      "ELK GROVE        Condo           114666.666667\n",
      "                 Residential     279851.638889\n",
      "ELVERTA          Residential     132866.000000\n",
      "FAIR OAKS        Condo           142500.000000\n",
      "                 Residential     323625.750000\n",
      "FOLSOM           Condo           240000.000000\n",
      "                 Residential     425895.187500\n",
      "FORESTHILL       Residential     194818.000000\n",
      "GALT             Residential     236943.428571\n",
      "GARDEN VALLEY    Residential     490000.000000\n",
      "GOLD RIVER       Condo           300000.000000\n",
      "                 Residential     377333.333333\n",
      "GRANITE BAY      Residential     678733.333333\n",
      "GREENWOOD        Residential     395000.000000\n",
      "LINCOLN          Condo           163000.000000\n",
      "                 Residential      94640.385714\n",
      "LOOMIS           Residential     567000.000000\n",
      "MATHER           Residential     237800.000000\n",
      "MEADOW VISTA     Residential     230000.000000\n",
      "NORTH HIGHLANDS  Residential     135659.333333\n",
      "ORANGEVALE       Residential     279159.545455\n",
      "PENRYN           Residential     506688.000000\n",
      "PLACERVILLE      Residential     363863.400000\n",
      "POLLOCK PINES    Residential     240302.666667\n",
      "RANCHO CORDOVA   Condo            94905.000000\n",
      "                 Multi-Family    236000.000000\n",
      "                 Residential     270940.807692\n",
      "RANCHO MURIETA   Residential     297750.000000\n",
      "RIO LINDA        Residential     172727.615385\n",
      "ROCKLIN          Residential     381835.823529\n",
      "ROSEVILLE        Condo           192071.428571\n",
      "                 Residential     347142.829268\n",
      "SACRAMENTO       Condo           137690.703704\n",
      "                 Multi-Family    214189.700000\n",
      "                 Residential     201359.584577\n",
      "SHINGLE SPRINGS  Unkown          275000.000000\n",
      "SLOUGHHOUSE      Residential       2000.000000\n",
      "WALNUT GROVE     Residential     380000.000000\n",
      "WEST SACRAMENTO  Residential     170700.000000\n",
      "WILTON           Residential     617508.400000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv('Sacramentorealestatetransactions.csv')\n",
    "\n",
    "# we can use dataframe like this to group by state and by type\n",
    "groups = df.groupby(['city', 'type'])\n",
    "\n",
    "# To print the mean price for each city and type\n",
    "print(groups['price'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc7c83",
   "metadata": {},
   "source": [
    "### 10) For each city, each type, find the highest, median and lowest transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73d7ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 max    median     min\n",
      "city            type                                  \n",
      "ANTELOPE        Condo         115000  115000.0  115000\n",
      "                Residential   408431  232600.0  126640\n",
      "AUBURN          Condo         260000  260000.0  260000\n",
      "                Multi-Family  285000  285000.0  285000\n",
      "                Residential   560000  504000.0  420454\n",
      "CAMERON PARK    Condo         119000  119000.0  119000\n",
      "                Residential   425000  219750.0  195000\n",
      "CARMICHAEL      Condo         250134  182000.0  139500\n",
      "                Residential   668365  266000.0  181872\n",
      "CITRUS HEIGHTS  Condo         116250   92625.0   69000\n",
      "                Multi-Family  256054  256054.0  256054\n",
      "                Residential   305000  191268.0   30000\n",
      "COOL            Residential   300000  300000.0  300000\n",
      "DIAMOND SPRINGS Residential   216033  216033.0  216033\n",
      "EL DORADO       Residential   289000  247000.0  205000\n",
      "EL DORADO HILLS Residential   879000  471000.0  235738\n",
      "ELK GROVE       Condo         145000  116500.0   71000\n",
      "                Residential   510000  258000.0  152000\n",
      "ELVERTA         Residential   140000  132732.0  126000\n",
      "FAIR OAKS       Condo         142500  142500.0  142500\n",
      "                Residential   680000  258006.5  185000\n",
      "FOLSOM          Condo         240000  240000.0  240000\n",
      "                Residential   636000  443500.0  200000\n",
      "FORESTHILL      Residential   194818  194818.0  194818\n",
      "GALT            Residential   420000  220000.0  106716\n",
      "GARDEN VALLEY   Residential   490000  490000.0  490000\n",
      "GOLD RIVER      Condo         300000  300000.0  300000\n",
      "                Residential   528000  305000.0  299000\n",
      "GRANITE BAY     Residential   760000  676200.0  600000\n",
      "GREENWOOD       Residential   395000  395000.0  395000\n",
      "LINCOLN         Condo         188000  163000.0  138000\n",
      "                Residential   512000    4897.0    1551\n",
      "LOOMIS          Residential   839000  567000.0  295000\n",
      "MATHER          Residential   237800  237800.0  237800\n",
      "MEADOW VISTA    Residential   230000  230000.0  230000\n",
      "NORTH HIGHLANDS Residential   224252  129000.0   63000\n",
      "ORANGEVALE      Residential   475000  252155.0  183200\n",
      "PENRYN          Residential   506688  506688.0  506688\n",
      "PLACERVILLE     Residential   677048  325000.0  205000\n",
      "POLLOCK PINES   Residential   280908  265000.0  175000\n",
      "RANCHO CORDOVA  Condo          94905   94905.0   94905\n",
      "                Multi-Family  236000  236000.0  236000\n",
      "                Residential   430000  281028.0  115000\n",
      "RANCHO MURIETA  Residential   425000  370500.0   97750\n",
      "RIO LINDA       Residential   300000  164000.0   30000\n",
      "ROCKLIN         Residential   600000  370000.0  230095\n",
      "ROSEVILLE       Condo         350000  170000.0  115000\n",
      "                Residential   614000  326951.0  160000\n",
      "SACRAMENTO      Condo         360000  110700.0   40000\n",
      "                Multi-Family  416767  187290.0  100000\n",
      "                Residential   699000  180000.0   55422\n",
      "SHINGLE SPRINGS Unkown        275000  275000.0  275000\n",
      "SLOUGHHOUSE     Residential     2000    2000.0    2000\n",
      "WALNUT GROVE    Residential   380000  380000.0  380000\n",
      "WEST SACRAMENTO Residential   200100  165000.0  147000\n",
      "WILTON          Residential   884790  579093.0  372000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv('Sacramentorealestatetransactions.csv')\n",
    "\n",
    "# Group the data first by city name, then by type, and calculate\n",
    "# the highest, median, and lowest transactions for each group\n",
    "group = df.groupby(['city', 'type'])['price'].agg(['max', 'median', 'min'])\n",
    "\n",
    "# Print the result\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f839c",
   "metadata": {},
   "source": [
    "### 11) For each zipcode and each type, find average transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e534c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip    type        \n",
      "95603  Condo           260000.000000\n",
      "       Multi-Family    285000.000000\n",
      "       Residential     494818.000000\n",
      "95608  Condo           190544.666667\n",
      "       Residential     314238.882353\n",
      "                           ...      \n",
      "95842  Multi-Family    179580.000000\n",
      "       Residential     157920.812500\n",
      "95843  Condo           115000.000000\n",
      "       Residential     236168.156250\n",
      "95864  Residential     364400.000000\n",
      "Name: price, Length: 101, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv('Sacramentorealestatetransactions.csv')\n",
    "\n",
    "# Group the data first by zip code, then by type, and calculate\n",
    "# the average transaction for each group\n",
    "group = df.groupby(['zip', 'type'])['price'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
